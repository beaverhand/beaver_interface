{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"../config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-20 16:18:02,263\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-20 16:18:08 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.\n",
      "WARNING 11-20 16:18:08 config.py:428] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 11-20 16:18:08 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='Qwen/Qwen2.5-7B-Instruct-AWQ', speculative_config=None, tokenizer='Qwen/Qwen2.5-7B-Instruct-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-7B-Instruct-AWQ, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n",
      "INFO 11-20 16:18:10 selector.py:261] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 11-20 16:18:10 selector.py:144] Using XFormers backend.\n",
      "INFO 11-20 16:18:11 model_runner.py:1072] Starting to load model Qwen/Qwen2.5-7B-Instruct-AWQ...\n",
      "INFO 11-20 16:18:12 weight_utils.py:243] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.20s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.14it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-20 16:19:50 model_runner.py:1077] Loading model weights took 5.2035 GB\n",
      "INFO 11-20 16:19:55 worker.py:232] Memory profiling results: total_gpu_memory=14.57GiB initial_memory_usage=5.48GiB peak_torch_memory=6.65GiB memory_usage_post_profile=5.51GiB non_torch_memory=0.30GiB kv_cache_size=6.89GiB gpu_memory_utilization=0.95\n",
      "INFO 11-20 16:19:55 gpu_executor.py:113] # GPU blocks: 8066, # CPU blocks: 4681\n",
      "INFO 11-20 16:19:55 gpu_executor.py:117] Maximum concurrency for 8192 tokens per request: 15.75x\n",
      "INFO 11-20 16:19:59 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 11-20 16:19:59 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 11-20 16:20:29 model_runner.py:1518] Graph capturing finished in 30 secs, took 0.50 GiB\n"
     ]
    }
   ],
   "source": [
    "# from huggingface_hub import login\n",
    "# login(\"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\")\n",
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(**config.get(\"llm_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def preprocess_text(x):\n",
    "    x = re.sub(\"http\\w+\", '',x)   # Delete URL\n",
    "    x = re.sub(r\"\\.+\", \".\", x)    # Replace consecutive commas and periods with one comma and period character\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    x = re.sub(r\"\\\\\\(\", \" \", x)\n",
    "    x = re.sub(r\"\\\\\\)\", \" \", x)\n",
    "    x = re.sub(r\"[ ]{1,}\", \" \", x)\n",
    "    x = x.strip()                 # Remove empty characters at the beginning and end\n",
    "    return x\n",
    "\n",
    "def apply_template( template, resume):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": preprocess_text(template.format(\n",
    "                Resume = resume,\n",
    "            ))\n",
    "        }\n",
    "    ]\n",
    "    return messages[0]['content']\n",
    "\n",
    "\n",
    "tempelate = '''Here is a resume of a potential candidate:\n",
    "{Resume}\n",
    "\n",
    "You are a human resource recruiting manager. Your task is to produce a professional response about the candidate's work experience. \n",
    "You are expected to be factual and accurate, without appending to the information.\n",
    "Generate a short professional report of 5-6 sentences about the candidate's work experience.\n",
    "'''\n",
    "\n",
    "resume = '''Arindam Roy\n",
    "New Delhi | +91-9310294033 | arindamroy11235@gmail.com | www.linkedin.com/in/royari | www.github.com/ArindamRoy23 | www.kaggle.com/arindamroy23 \n",
    "\n",
    "WORK EXPERIENCE\n",
    "Beaverhand\t Remote\n",
    "Data Scientist\t06/2024 – Present\n",
    "●\tDesigned RAG frameworks aimed at optimizing token generation and reducing computational overhead for future applications.\n",
    "●\tDeveloping algorithms to synchronize speech and facial movements in digital avatars, driving significant advancements in the realism and engagement of digital media.\n",
    "●\tGoogle cloud startup summit contest winner.\n",
    "\n",
    "Sanofi\t Paris\n",
    "Data Scientist - Intern\t07/2023 – 12/2023\n",
    "●\tDeveloped and tuned models to enhance omnichannel marketing communication, building upon previous research findings, spearheading two impactful projects—Omnichannel Marketing Optimization and Marketing Mix Modeling (MMx).\n",
    "●\tTuned and deployed attention-based model for Omnichannel Marketing Optimization, leveraging the transformer architecture for marketing sequence classification, yielding in a predictive tool for business to better plan future marketing activities. \n",
    "●\tAssisted in implementation Mix Market Model ROI forecasting models for marketing data, contributing to informed decision-making and future campaign budget planning. Led initiatives to performance optimize MMx pipeline, integrating GPU acceleration and PySpark implementation, resulting in improved runtime efficiency.\n",
    "\n",
    "Sanofi | Atos\t Paris\n",
    "Corporate Researcher: Marketing Optimization\t01/2023 – 06/2023\n",
    "●\tConducted research in partnership with Atos to enhance marketing strategies for healthcare practitioners.\n",
    "●\tDeveloped Snowflake-based data pipelines for preparing model-ready data and enabling future machine learning solutions.\n",
    "●\tBuilt a regression-based statistical model to evaluate and prioritize marketing initiatives, laying the groundwork for advanced marketing insights.\n",
    "●\tProposed multiple machine learning and deep learning models for optimizing marketing strategies.\n",
    "\n",
    "Deloitte US\t Bengaluru\n",
    "Data Analyst – Supply Chain (PLM/MES)\t01/2019 –/07/2022\n",
    "●\tDesigned ETL pipelines with Python for data migration to Oracle Cloud, improving data visibility and operational efficiency.\n",
    "●\tDeveloped computer vision tools using the Camelot package to extract unstructured packaging data from PDFs, reducing manual effort and accelerating project timelines by 30%.\n",
    "●\tCreated an explainable Random Forest-based order failure prediction model, achieving 70% accuracy, and integrated it with SAP using BluePrism RPA to reduce churn time for a major server manufacturer.\n",
    "●\tOptimized manufacturing execution system (MES) logic for factory floor operations, enhancing real-time data capture and production efficiency.\n",
    "●\tEarned two promotions to Consultant, consistently ranked in the top 10% of Deloitte’s supply chain division for three consecutive years.\n",
    "\n",
    "EDUCATION\n",
    "CentraleSupélec & ESSEC Business School\tParis\n",
    "Master of Science in Data Science and Business Analytics\t08/2022 – 12/2023\n",
    "●\tMajor in Data Science with minor in Business Analytics with overall GPA of 15.2/20\n",
    "●\tWinner of cohort Hackathon\n",
    "\n",
    "Manipal Institute of Technology\tManipal\n",
    "Bachelor of Technology in Mechanical and Manufacturing Engineering\t08/2015 – 06/2019\n",
    "●\tMinor in machine design with overall GPA of 7/10\n",
    "\n",
    "PROJECT WORK\n",
    "CentraleSupélec: Recommender System with LLM\t\n",
    "\n",
    "Kaggle: LLM Generated Text Detection (Bronze Medal), Misconception Mining, Lumbar Spine Degenerative Classification, BirdCLEF\t\n",
    "\n",
    "CERTIFICATIONS & ACHIEVEMENTS\n",
    "●\tKaggle Expert (Competition & Notebook)\n",
    "●\tWinner of DSBA cohort Hackathon \n",
    "●\tSpecialization: Mathematics for Machine Learning (Imperial College – London | Coursera)\n",
    "●\tGRE (Score 323), IELTS (Band 7.5)\n",
    "\n",
    "SKILLS & INTERESTS\n",
    "Interest: Machine Learning, Deep Learning, Optimization, Graph Methods, Data Mining, ETL, Supply Chain Analytics, Data Engineering, ML Ops\n",
    "Skills: Python, SQL, R, NoSQL(MongoDB) , PySpark, Pytorch, Keras TF, Statistics, Tableau, PowerBI, Databricks, Snowflake, Alteryx, SAP BODS, SAP PLM, Siemens OpCenter\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = apply_template(tempelate, resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a resume of a potential candidate:\n",
      "Arindam Roy\n",
      "New Delhi | +91-9310294033 | arindamroy11235@gmail.com | www.linkedin.com/in/royari | www.github.com/ArindamRoy23 | www.kaggle.com/arindamroy23 \n",
      "\n",
      "WORK EXPERIENCE\n",
      "Beaverhand\t Remote\n",
      "Data Scientist\t06/2024 – Present\n",
      "●\tDesigned RAG frameworks aimed at optimizing token generation and reducing computational overhead for future applications.\n",
      "●\tDeveloping algorithms to synchronize speech and facial movements in digital avatars, driving significant advancements in the realism and engagement of digital media.\n",
      "●\tGoogle cloud startup summit contest winner.\n",
      "\n",
      "Sanofi\t Paris\n",
      "Data Scientist - Intern\t07/2023 – 12/2023\n",
      "●\tDeveloped and tuned models to enhance omnichannel marketing communication, building upon previous research findings, spearheading two impactful projects—Omnichannel Marketing Optimization and Marketing Mix Modeling (MMx).\n",
      "●\tTuned and deployed attention-based model for Omnichannel Marketing Optimization, leveraging the transformer architecture for marketing sequence classification, yielding in a predictive tool for business to better plan future marketing activities. \n",
      "●\tAssisted in implementation Mix Market Model ROI forecasting models for marketing data, contributing to informed decision-making and future campaign budget planning. Led initiatives to performance optimize MMx pipeline, integrating GPU acceleration and PySpark implementation, resulting in improved runtime efficiency.\n",
      "\n",
      "Sanofi | Atos\t Paris\n",
      "Corporate Researcher: Marketing Optimization\t01/2023 – 06/2023\n",
      "●\tConducted research in partnership with Atos to enhance marketing strategies for healthcare practitioners.\n",
      "●\tDeveloped Snowflake-based data pipelines for preparing model-ready data and enabling future machine learning solutions.\n",
      "●\tBuilt a regression-based statistical model to evaluate and prioritize marketing initiatives, laying the groundwork for advanced marketing insights.\n",
      "●\tProposed multiple machine learning and deep learning models for optimizing marketing strategies.\n",
      "\n",
      "Deloitte US\t Bengaluru\n",
      "Data Analyst – Supply Chain (PLM/MES)\t01/2019 –/07/2022\n",
      "●\tDesigned ETL pipelines with Python for data migration to Oracle Cloud, improving data visibility and operational efficiency.\n",
      "●\tDeveloped computer vision tools using the Camelot package to extract unstructured packaging data from PDFs, reducing manual effort and accelerating project timelines by 30%.\n",
      "●\tCreated an explainable Random Forest-based order failure prediction model, achieving 70% accuracy, and integrated it with SAP using BluePrism RPA to reduce churn time for a major server manufacturer.\n",
      "●\tOptimized manufacturing execution system (MES) logic for factory floor operations, enhancing real-time data capture and production efficiency.\n",
      "●\tEarned two promotions to Consultant, consistently ranked in the top 10% of Deloitte’s supply chain division for three consecutive years.\n",
      "\n",
      "EDUCATION\n",
      "CentraleSupélec & ESSEC Business School\tParis\n",
      "Master of Science in Data Science and Business Analytics\t08/2022 – 12/2023\n",
      "●\tMajor in Data Science with minor in Business Analytics with overall GPA of 15.2/20\n",
      "●\tWinner of cohort Hackathon\n",
      "\n",
      "Manipal Institute of Technology\tManipal\n",
      "Bachelor of Technology in Mechanical and Manufacturing Engineering\t08/2015 – 06/2019\n",
      "●\tMinor in machine design with overall GPA of 7/10\n",
      "\n",
      "PROJECT WORK\n",
      "CentraleSupélec: Recommender System with LLM\t\n",
      "\n",
      "Kaggle: LLM Generated Text Detection (Bronze Medal), Misconception Mining, Lumbar Spine Degenerative Classification, BirdCLEF\t\n",
      "\n",
      "CERTIFICATIONS & ACHIEVEMENTS\n",
      "●\tKaggle Expert (Competition & Notebook)\n",
      "●\tWinner of DSBA cohort Hackathon \n",
      "●\tSpecialization: Mathematics for Machine Learning (Imperial College – London | Coursera)\n",
      "●\tGRE (Score 323), IELTS (Band 7.5)\n",
      "\n",
      "SKILLS & INTERESTS\n",
      "Interest: Machine Learning, Deep Learning, Optimization, Graph Methods, Data Mining, ETL, Supply Chain Analytics, Data Engineering, ML Ops\n",
      "Skills: Python, SQL, R, NoSQL(MongoDB) , PySpark, Pytorch, Keras TF, Statistics, Tableau, PowerBI, Databricks, Snowflake, Alteryx, SAP BODS, SAP PLM, Siemens OpCenter\n",
      "\n",
      "\n",
      "You are a human resource recruiting manager. Your task is to produce a professional response about the candidate's work experience. \n",
      "You are expected to be factual and accurate, without appending to the information.\n",
      "Generate a short professional report of 5-6 sentences about the candidate's work experience.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.46s/it, est. speed input: 46.87 toks/s, output: 23.86 toks/s]\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(max_tokens=512, \n",
    "                                 temperature=0.2, \n",
    "                                 top_p=0.5)\n",
    "response = llm.generate(prompt, sampling_params)\n",
    "# print(response[0].outputs[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arindam Roy has extensive experience in data science, including roles at Beaverhand, Sanofi, and Deloitte. At Beaverhand, he designed RAG frameworks and developed algorithms for digital avatars. His internships at Sanofi involved developing models for omnichannel marketing and optimizing GPU acceleration. At Deloitte, he focused on supply chain analytics, developing computer vision tools and explainable machine learning models. His roles demonstrate a strong background in data science, machine learning, and supply chain optimization. Arindam's experience spans both industry and academia, showcasing his versatility and expertise. Arindam's work experience highlights his proficiency in data science, machine learning, and supply chain optimization, with roles at Beaverhand, Sanofi, and Deloitte. His projects include designing RAG frameworks, developing algorithms for digital avatars, and creating explainable machine learning models. His internships at Sanofi focused on enhancing omnichannel marketing and optimizing GPU acceleration. At Deloitte, he worked on supply chain analytics, developing computer vision tools, and creating order failure prediction models. Arindam's diverse experience demonstrates his capability in various data science domains. Arindam's roles at Beaverhand, Sanofi, and Deloitte underscore his expertise in data science, machine learning, and supply chain optimization. His projects include designing RAG frameworks, developing algorithms for digital avatars, and creating explainable machine learning models. His internships at Sanofi involved enhancing omnichannel marketing and optimizing GPU acceleration. At Deloitte, he focused on supply chain analytics, developing computer vision tools, and creating order failure prediction models. Arindam's experience showcases his versatility and proficiency in multiple areas of data science. Arindam Roy's work experience spans various roles in data science, including at Beaverhand, Sanofi, and Deloitte. At Beaverhand, he designed RAG frameworks and developed algorithms for digital avatars. His internships at Sanofi involved creating models for omnichannel marketing and optimizing GPU acceleration. At Deloitte, he focused on supply chain analytics, developing computer vision tools, and creating explainable machine learning models. His diverse experience highlights his expertise in data science, machine learning, and supply chain optimization. Arindam's roles demonstrate his capability in designing and implementing advanced data science solutions. Arindam Roy's extensive experience in data science includes roles at Beaverhand, Sanofi, and Deloitte. At Beaverhand, he designed RAG frameworks and developed algorithms for digital avatars. His intern\n"
     ]
    }
   ],
   "source": [
    "print(response[0].outputs[0].text.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
